#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Force-refresh Taiwan stock price data from 2010 onward.

This script hits the backend `/api/update` endpoint in batches with
`force_full_refresh=True` so each symbol is re-downloaded starting from
2010-01-01 up to today.

Usage examples:
    python3 full_refresh_2010.py                # default settings
    python3 full_refresh_2010.py --batch-size 5 # smaller batches
    python3 full_refresh_2010.py --start-index 50 --limit 100  # partial run
"""

from __future__ import annotations

import argparse
import math
import sys
import time
from datetime import datetime
from typing import Iterable, List

import requests

API_BASE = "http://localhost:5003"
DEFAULT_START_DATE = "2010-01-01"
BATCH_SIZE_DEFAULT = 10
REQUEST_TIMEOUT = 900  # seconds
SLEEP_BETWEEN_BATCHES = 3  # seconds


def fetch_all_symbols() -> List[str]:
    """Retrieve the complete symbol list from the backend."""
    resp = requests.get(f"{API_BASE}/api/symbols", timeout=30)
    resp.raise_for_status()
    payload = resp.json()
    symbols = [item["symbol"] for item in payload.get("data", [])]
    if not symbols:
        raise RuntimeError("å¾Œç«¯å›å‚³çš„è‚¡ç¥¨æ¸…å–®ç‚ºç©ºï¼Œç„¡æ³•é€²è¡Œå›è£œ")
    return symbols


def batched(iterable: Iterable[str], size: int) -> Iterable[List[str]]:
    """Yield lists of length <= size from iterable."""
    batch: List[str] = []
    for value in iterable:
        batch.append(value)
        if len(batch) == size:
            yield batch
            batch = []
    if batch:
        yield batch


def run_batch(batch_symbols: List[str], batch_idx: int, total_batches: int) -> bool:
    """Send one /api/update request for the given batch of symbols."""
    print("=" * 70)
    print(f"ğŸ“¦ æ‰¹æ¬¡ {batch_idx}/{total_batches} | è‚¡ç¥¨æ•¸: {len(batch_symbols)}")
    preview = ", ".join(batch_symbols[:5])
    if len(batch_symbols) > 5:
        preview += "..."
    print(f"ğŸ“‹ è‚¡ç¥¨: {preview}")
    print("=" * 70)

    payload = {
        "symbols": batch_symbols,
        "start_date": DEFAULT_START_DATE,
        "end_date": datetime.now().strftime("%Y-%m-%d"),
        "update_prices": True,
        "force_full_refresh": True,
        "force_start_date": DEFAULT_START_DATE,
    }

    try:
        print(f"â³ ç™¼é€è«‹æ±‚è‡³å¾Œç«¯ API...")
        start_time = time.time()
        resp = requests.post(
            f"{API_BASE}/api/update",
            json=payload,
            timeout=REQUEST_TIMEOUT,
        )
        elapsed = time.time() - start_time
        resp.raise_for_status()
        result = resp.json()
        
        if not result.get("success", False):
            print("âœ— æ‰¹æ¬¡å¤±æ•—: å¾Œç«¯å›å‚³ success=false")
            print(result)
            return False

        # é¡¯ç¤ºæ¯ä¸€æª”è‚¡ç¥¨çš„è©³ç´°è³‡è¨Š
        results = result.get("results", [])
        errors = result.get("errors", [])
        
        print(f"\nâ±ï¸  API å›æ‡‰æ™‚é–“: {elapsed:.1f} ç§’")
        print(f"\nğŸ“Š å„è‚¡ç¥¨æŠ“å–è©³æƒ…:")
        print("-" * 70)
        
        for i, stock_result in enumerate(results, 1):
            symbol = stock_result.get("symbol", "æœªçŸ¥")
            status = stock_result.get("status", "unknown")
            
            # å–å¾—è¨˜éŒ„æ•¸è³‡è¨Š
            new_records = stock_result.get("price_records", 0)
            duplicate_records = stock_result.get("duplicate_records", 0)
            existing_records = stock_result.get("existing_records", 0)
            
            # å–å¾—æ—¥æœŸç¯„åœ
            date_range = stock_result.get("price_date_range", {})
            start_date = date_range.get("start", "N/A")
            end_date = date_range.get("end", "N/A")
            trading_days = date_range.get("trading_days_count", 0)
            
            # ç‹€æ…‹åœ–ç¤º
            status_icon = "âœ“" if status == "success" else "âš ï¸"
            
            # é¡¯ç¤ºè‚¡ç¥¨è³‡è¨Š
            print(f"{status_icon} [{i}/{len(results)}] {symbol}")
            print(f"   â””â”€ æ–°å¢: {new_records:>4} ç­† | é‡è¤‡: {duplicate_records:>4} ç­† | ç¸½è¨ˆ: {existing_records:>4} ç­†")
            
            if trading_days > 0:
                print(f"   â””â”€ æ—¥æœŸ: {start_date} ~ {end_date} ({trading_days} å€‹äº¤æ˜“æ—¥)")
            else:
                print(f"   â””â”€ ç„¡æ–°æ•¸æ“š")
        
        print("-" * 70)
        
        # æ‰¹æ¬¡æ‘˜è¦
        total_new = sum(r.get("price_records", 0) for r in results)
        total_duplicate = sum(r.get("duplicate_records", 0) for r in results)
        
        print(f"\nâœ… æ‰¹æ¬¡å®Œæˆ | æˆåŠŸ: {len(results)} æª”")
        print(f"   ç¸½æ–°å¢è¨˜éŒ„: {total_new:,} ç­†")
        print(f"   ç¸½é‡è¤‡è¨˜éŒ„: {total_duplicate:,} ç­†")
        
        if errors:
            print(f"\nâŒ å¤±æ•—: {len(errors)} æª”")
            for error in errors:
                print(f"   - {error}")
            return False
        
        return True
        
    except requests.exceptions.RequestException as exc:
        print(f"\nâœ— æ‰¹æ¬¡å¤±æ•— (HTTP ä¾‹å¤–): {exc}")
        return False
    except ValueError as exc:
        print(f"\nâœ— æ‰¹æ¬¡å¤±æ•— (JSON è§£æéŒ¯èª¤): {exc}")
        if 'resp' in locals():
            print(f"å›æ‡‰å…§å®¹: {resp.text[:500]}")
        return False
    except Exception as exc:
        print(f"\nâœ— æ‰¹æ¬¡å¤±æ•— (æœªé æœŸéŒ¯èª¤): {exc}")
        return False


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="å¼·åˆ¶å›è£œ 2010 å¹´èµ·çš„è‚¡ç¥¨æ•¸æ“š")
    parser.add_argument(
        "--batch-size",
        type=int,
        default=BATCH_SIZE_DEFAULT,
        help=f"æ¯æ‰¹è™•ç†çš„è‚¡ç¥¨æ•¸é‡ (é è¨­ {BATCH_SIZE_DEFAULT})",
    )
    parser.add_argument(
        "--start-index",
        type=int,
        default=0,
        help="å¾ç¬¬å¹¾æª”è‚¡ç¥¨é–‹å§‹ (ç”¨æ–¼çºŒè·‘)",
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="æœ€å¤šè™•ç†å¤šå°‘æª”è‚¡ç¥¨ (é è¨­å…¨éƒ¨)",
    )
    return parser.parse_args()


def main() -> int:
    args = parse_args()
    try:
        symbols = fetch_all_symbols()
    except Exception as exc:  # noqa: BLE001 - é¡¯ç¤ºæ˜ç¢ºéŒ¯èª¤
        print(f"âœ— ç„¡æ³•å–å¾—è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨: {exc}")
        return 1

    if args.start_index >= len(symbols):
        print("âœ— start-index å¤§æ–¼è‚¡ç¥¨æ¸…å–®é•·åº¦")
        return 1

    symbols = symbols[args.start_index :]
    if args.limit is not None:
        symbols = symbols[: args.limit]

    total_symbols = len(symbols)
    if total_symbols == 0:
        print("âœ— æ²’æœ‰è¦è™•ç†çš„è‚¡ç¥¨")
        return 1

    batches = list(batched(symbols, max(args.batch_size, 1)))
    total_batches = len(batches)

    print("=" * 70)
    print("å¼·åˆ¶å›è£œå°ç£è‚¡ç¥¨æ•¸æ“š (2010-01-01 èµ·) é–‹å§‹")
    print(f"ç¸½è‚¡ç¥¨æ•¸: {total_symbols}")
    print(f"æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"ç¸½æ‰¹æ¬¡: {total_batches}")
    print("=" * 70)

    start_ts = time.time()
    success_batches = 0
    failed_batches = 0
    total_new_records = 0
    total_processed_symbols = 0

    for idx, batch in enumerate(batches, start=1):
        batch_start = time.time()
        ok = run_batch(batch, idx, total_batches)
        batch_duration = time.time() - batch_start
        
        if ok:
            success_batches += 1
            total_processed_symbols += len(batch)
        else:
            failed_batches += 1
        
        # é€²åº¦çµ±è¨ˆ
        completed_pct = (idx / total_batches) * 100
        elapsed = time.time() - start_ts
        avg_time_per_batch = elapsed / idx
        remaining_batches = total_batches - idx
        eta_seconds = remaining_batches * avg_time_per_batch
        
        print(f"\nğŸ“Š ç¸½é€²åº¦: {idx}/{total_batches} ({completed_pct:.1f}%)")
        print(f"â±ï¸  å·²ç¶“é: {elapsed/60:.1f} åˆ†é˜ | é ä¼°å‰©é¤˜: {eta_seconds/60:.1f} åˆ†é˜")
        print(f"âœ… æˆåŠŸ: {success_batches} æ‰¹ | âŒ å¤±æ•—: {failed_batches} æ‰¹")
        
        if idx < total_batches:
            print(f"\nâ¸ï¸  ç­‰å¾… {SLEEP_BETWEEN_BATCHES} ç§’å¾Œé€²è¡Œä¸‹ä¸€æ‰¹...\n")
            time.sleep(SLEEP_BETWEEN_BATCHES)

    duration = time.time() - start_ts
    success_rate = (success_batches / total_batches * 100) if total_batches > 0 else 0
    
    print("\n" + "=" * 70)
    print("ğŸ‰ å›è£œæµç¨‹å®Œæˆ")
    print("=" * 70)
    print(f"ğŸ“Š çµ±è¨ˆæ‘˜è¦:")
    print(f"   ç¸½æ‰¹æ¬¡æ•¸: {total_batches}")
    print(f"   æˆåŠŸæ‰¹æ¬¡: {success_batches} ({success_rate:.1f}%)")
    print(f"   å¤±æ•—æ‰¹æ¬¡: {failed_batches}")
    print(f"   è™•ç†è‚¡ç¥¨: {total_processed_symbols}/{total_symbols}")
    print(f"\nâ±ï¸  æ™‚é–“çµ±è¨ˆ:")
    print(f"   ç¸½è€—æ™‚: {duration/60:.1f} åˆ†é˜ ({duration/3600:.2f} å°æ™‚)")
    print(f"   å¹³å‡æ¯æ‰¹: {duration/total_batches:.1f} ç§’")
    if total_processed_symbols > 0:
        print(f"   å¹³å‡æ¯æª”: {duration/total_processed_symbols:.1f} ç§’")
    print("=" * 70)

    return 0 if failed_batches == 0 else 2


if __name__ == "__main__":
    sys.exit(main())

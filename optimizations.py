#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç³»ç»Ÿä¼˜åŒ–æ¨¡å—
æä¾›æ•°æ®åº“é”ã€ç¼“å­˜ã€è¿›åº¦è¿½è¸ªç­‰åŠŸèƒ½
"""

import threading
import time
from datetime import datetime, timedelta
from functools import lru_cache
from collections import defaultdict
import logging

logger = logging.getLogger(__name__)

# ============================================================================
# 1. æ•°æ®åº“å¹¶å‘æ§åˆ¶
# ============================================================================

class DatabaseLockManager:
    """æ•°æ®åº“é”ç®¡ç†å™¨ - é˜²æ­¢å¹¶å‘æ­»é”"""
    
    def __init__(self):
        self.table_lock = threading.Lock()
        self.write_lock = threading.Semaphore(3)  # æœ€å¤š3ä¸ªå¹¶å‘å†™å…¥
        
    def acquire_table_lock(self):
        """è·å–è¡¨ç»“æ„ä¿®æ”¹é”"""
        return self.table_lock.acquire(timeout=30)
    
    def release_table_lock(self):
        """é‡Šæ”¾è¡¨ç»“æ„ä¿®æ”¹é”"""
        self.table_lock.release()
    
    def acquire_write_lock(self):
        """è·å–å†™å…¥é”"""
        return self.write_lock.acquire(timeout=60)
    
    def release_write_lock(self):
        """é‡Šæ”¾å†™å…¥é”"""
        self.write_lock.release()


# å…¨å±€é”å®ä¾‹
db_lock_manager = DatabaseLockManager()


# ============================================================================
# 2. API è¯·æ±‚ç¼“å­˜
# ============================================================================

class APICache:
    """API è¯·æ±‚ç¼“å­˜ - å‡å°‘é‡å¤è¯·æ±‚"""
    
    def __init__(self, ttl=3600):
        self.cache = {}
        self.ttl = ttl  # ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰
        self.lock = threading.Lock()
    
    def get(self, key):
        """è·å–ç¼“å­˜"""
        with self.lock:
            if key in self.cache:
                data, timestamp = self.cache[key]
                # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
                if time.time() - timestamp < self.ttl:
                    logger.debug(f"ç¼“å­˜å‘½ä¸­: {key}")
                    return data
                else:
                    # è¿‡æœŸï¼Œåˆ é™¤
                    del self.cache[key]
        return None
    
    def set(self, key, data):
        """è®¾ç½®ç¼“å­˜"""
        with self.lock:
            self.cache[key] = (data, time.time())
            logger.debug(f"ç¼“å­˜è®¾ç½®: {key}")
    
    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        with self.lock:
            self.cache.clear()
            logger.info("ç¼“å­˜å·²æ¸…ç©º")
    
    def get_stats(self):
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        with self.lock:
            total = len(self.cache)
            expired = sum(
                1 for _, timestamp in self.cache.values()
                if time.time() - timestamp >= self.ttl
            )
            return {
                'total': total,
                'valid': total - expired,
                'expired': expired
            }


# å…¨å±€ç¼“å­˜å®ä¾‹
api_cache = APICache(ttl=3600)  # 1å°æ—¶è¿‡æœŸ


# ============================================================================
# 3. è¿›åº¦è¿½è¸ªå™¨
# ============================================================================

class ProgressTracker:
    """è¿›åº¦è¿½è¸ªå™¨ - å®æ—¶æ˜¾ç¤ºæ›´æ–°è¿›åº¦"""
    
    def __init__(self, total, task_name="æ›´æ–°"):
        self.total = total
        self.task_name = task_name
        self.completed = 0
        self.failed = 0
        self.skipped = 0
        self.start_time = datetime.now()
        self.results = []
        self.lock = threading.Lock()
    
    def update(self, success=True, symbol=None, count=0, error=None):
        """æ›´æ–°è¿›åº¦"""
        with self.lock:
            if success:
                self.completed += 1
            else:
                self.failed += 1
            
            # è®°å½•ç»“æœ
            self.results.append({
                'symbol': symbol,
                'success': success,
                'count': count,
                'error': str(error) if error else None,
                'time': datetime.now()
            })
            
            # æ¯10ä¸ªæˆ–å¤±è´¥æ—¶è¾“å‡º
            if self.completed % 10 == 0 or not success:
                self.print_progress()
    
    def skip(self, symbol=None, reason=None):
        """è·³è¿‡æŸä¸ªé¡¹ç›®"""
        with self.lock:
            self.skipped += 1
            self.results.append({
                'symbol': symbol,
                'success': False,
                'skipped': True,
                'reason': reason,
                'time': datetime.now()
            })
    
    def print_progress(self):
        """æ‰“å°è¿›åº¦ä¿¡æ¯"""
        processed = self.completed + self.failed + self.skipped
        percentage = (processed / self.total * 100) if self.total > 0 else 0
        
        # è®¡ç®—å‰©ä½™æ—¶é—´
        elapsed = (datetime.now() - self.start_time).total_seconds()
        if processed > 0:
            avg_time = elapsed / processed
            remaining_seconds = (self.total - processed) * avg_time
            remaining_str = f"{int(remaining_seconds // 60)}åˆ†{int(remaining_seconds % 60)}ç§’"
        else:
            remaining_str = "è®¡ç®—ä¸­..."
        
        logger.info(
            f"ğŸ“Š {self.task_name} è¿›åº¦: {processed}/{self.total} ({percentage:.1f}%) | "
            f"âœ… {self.completed} âŒ {self.failed} â­ï¸ {self.skipped} | "
            f"â±ï¸ é¢„è®¡å‰©ä½™: {remaining_str}"
        )
    
    def get_summary(self):
        """è·å–æ‘˜è¦"""
        elapsed = (datetime.now() - self.start_time).total_seconds()
        
        return {
            'total': self.total,
            'completed': self.completed,
            'failed': self.failed,
            'skipped': self.skipped,
            'success_rate': (self.completed / self.total * 100) if self.total > 0 else 0,
            'elapsed_seconds': elapsed,
            'elapsed_str': f"{int(elapsed // 60)}åˆ†{int(elapsed % 60)}ç§’"
        }
    
    def print_summary(self):
        """æ‰“å°æ‘˜è¦"""
        summary = self.get_summary()
        
        logger.info("=" * 60)
        logger.info(f"ğŸ¯ {self.task_name} å®Œæˆæ‘˜è¦")
        logger.info("=" * 60)
        logger.info(f"æ€»æ•°: {summary['total']}")
        logger.info(f"âœ… æˆåŠŸ: {summary['completed']}")
        logger.info(f"âŒ å¤±è´¥: {summary['failed']}")
        logger.info(f"â­ï¸ è·³è¿‡: {summary['skipped']}")
        logger.info(f"æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        logger.info(f"â±ï¸ æ€»è€—æ—¶: {summary['elapsed_str']}")
        logger.info("=" * 60)


# ============================================================================
# 4. é”™è¯¯åˆ†ç±»å™¨
# ============================================================================

class ErrorClassifier:
    """é”™è¯¯åˆ†ç±»å™¨ - æ™ºèƒ½åˆ†ç±»å’Œå¤„ç†é”™è¯¯"""
    
    ERROR_TYPES = {
        'API_TIMEOUT': {
            'name': 'API è¶…æ—¶',
            'keywords': ['timeout', 'timed out'],
            'severity': 'warning',
            'retry': True
        },
        'API_500': {
            'name': 'API æœåŠ¡å™¨é”™è¯¯',
            'keywords': ['500', 'internal server error'],
            'severity': 'error',
            'retry': True
        },
        'API_404': {
            'name': 'API æœªæ‰¾åˆ°',
            'keywords': ['404', 'not found'],
            'severity': 'info',
            'retry': False
        },
        'PARSE_ERROR': {
            'name': 'æ•°æ®è§£æå¤±è´¥',
            'keywords': ['parse', 'convert', 'float'],
            'severity': 'warning',
            'retry': False
        },
        'DB_DEADLOCK': {
            'name': 'æ•°æ®åº“æ­»é”',
            'keywords': ['deadlock', 'transaction'],
            'severity': 'critical',
            'retry': True
        },
        'DB_CONSTRAINT': {
            'name': 'æ•°æ®åº“çº¦æŸ',
            'keywords': ['constraint', 'unique', 'foreign key'],
            'severity': 'warning',
            'retry': False
        },
        'NO_DATA': {
            'name': 'æ— æ•°æ®ï¼ˆåœç‰Œ/ä¸‹å¸‚ï¼‰',
            'keywords': ['no data', 'æ²¡æœ‰æŠ“åˆ°', '---'],
            'severity': 'info',
            'retry': False
        },
        'NETWORK_ERROR': {
            'name': 'ç½‘ç»œé”™è¯¯',
            'keywords': ['connection', 'network', 'dns'],
            'severity': 'error',
            'retry': True
        }
    }
    
    def __init__(self):
        self.error_counts = defaultdict(int)
        self.lock = threading.Lock()
    
    def classify(self, error):
        """åˆ†ç±»é”™è¯¯"""
        error_str = str(error).lower()
        
        for error_type, config in self.ERROR_TYPES.items():
            if any(keyword in error_str for keyword in config['keywords']):
                with self.lock:
                    self.error_counts[error_type] += 1
                return error_type, config
        
        # æœªçŸ¥é”™è¯¯
        with self.lock:
            self.error_counts['UNKNOWN'] += 1
        return 'UNKNOWN', {
            'name': 'æœªçŸ¥é”™è¯¯',
            'severity': 'error',
            'retry': False
        }
    
    def should_retry(self, error):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•"""
        error_type, config = self.classify(error)
        return config.get('retry', False)
    
    def get_statistics(self):
        """è·å–é”™è¯¯ç»Ÿè®¡"""
        with self.lock:
            return dict(self.error_counts)
    
    def print_statistics(self):
        """æ‰“å°é”™è¯¯ç»Ÿè®¡"""
        stats = self.get_statistics()
        if not stats:
            logger.info("âœ… æ— é”™è¯¯è®°å½•")
            return
        
        logger.info("=" * 60)
        logger.info("âš ï¸ é”™è¯¯ç»Ÿè®¡")
        logger.info("=" * 60)
        
        total = sum(stats.values())
        for error_type, count in sorted(stats.items(), key=lambda x: x[1], reverse=True):
            config = self.ERROR_TYPES.get(error_type, {})
            name = config.get('name', error_type)
            percentage = (count / total * 100) if total > 0 else 0
            logger.info(f"{name}: {count} æ¬¡ ({percentage:.1f}%)")
        
        logger.info("=" * 60)


# å…¨å±€é”™è¯¯åˆ†ç±»å™¨
error_classifier = ErrorClassifier()


# ============================================================================
# 5. æ™ºèƒ½æ‰¹æ¬¡è®¡ç®—å™¨
# ============================================================================

class BatchOptimizer:
    """æ‰¹æ¬¡ä¼˜åŒ–å™¨ - æ™ºèƒ½è®¡ç®—æœ€ä¼˜æ‰¹æ¬¡å¤§å°"""
    
    def __init__(self):
        self.history = []  # è®°å½•å†å²æ€§èƒ½
    
    def calculate_batch_size(self, total_items, days_per_item, target_time=45):
        """
        è®¡ç®—æœ€ä¼˜æ‰¹æ¬¡å¤§å°
        
        Args:
            total_items: æ€»é¡¹ç›®æ•°
            days_per_item: æ¯ä¸ªé¡¹ç›®çš„å¤©æ•°
            target_time: ç›®æ ‡æ‰¹æ¬¡æ—¶é—´ï¼ˆç§’ï¼‰
        
        Returns:
            æ‰¹æ¬¡å¤§å°
        """
        # ä¼°ç®—å•ä¸ªé¡¹ç›®æ—¶é—´
        time_per_item = days_per_item * 0.5 + 3  # API 0.5ç§’/å¤© + å†™å…¥3ç§’
        
        # è®¡ç®—æ‰¹æ¬¡å¤§å°
        batch_size = int(target_time / time_per_item)
        
        # é™åˆ¶èŒƒå›´
        batch_size = max(5, min(20, batch_size))
        
        # æ ¹æ®å†å²è°ƒæ•´
        if len(self.history) > 5:
            avg_actual = sum(h['actual_time'] for h in self.history[-5:]) / 5
            if avg_actual > target_time * 1.5:
                batch_size = int(batch_size * 0.8)  # å‡å°æ‰¹æ¬¡
            elif avg_actual < target_time * 0.5:
                batch_size = int(batch_size * 1.2)  # å¢å¤§æ‰¹æ¬¡
        
        return batch_size
    
    def record_performance(self, batch_size, items_count, actual_time):
        """è®°å½•å®é™…æ€§èƒ½"""
        self.history.append({
            'batch_size': batch_size,
            'items_count': items_count,
            'actual_time': actual_time,
            'timestamp': datetime.now()
        })
        
        # åªä¿ç•™æœ€è¿‘20æ¡è®°å½•
        if len(self.history) > 20:
            self.history = self.history[-20:]
    
    def get_recommendation(self, total_items, days_per_item):
        """è·å–æ‰¹æ¬¡å»ºè®®"""
        batch_size = self.calculate_batch_size(total_items, days_per_item)
        num_batches = (total_items + batch_size - 1) // batch_size
        
        time_per_batch = (days_per_item * 0.5 + 3) * batch_size
        total_time = time_per_batch * num_batches
        
        return {
            'batch_size': batch_size,
            'num_batches': num_batches,
            'estimated_time_per_batch': f"{int(time_per_batch // 60)}åˆ†{int(time_per_batch % 60)}ç§’",
            'estimated_total_time': f"{int(total_time // 60)}åˆ†{int(total_time % 60)}ç§’"
        }


# å…¨å±€æ‰¹æ¬¡ä¼˜åŒ–å™¨
batch_optimizer = BatchOptimizer()


# ============================================================================
# 6. ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

if __name__ == '__main__':
    # ç¤ºä¾‹ï¼šä½¿ç”¨è¿›åº¦è¿½è¸ªå™¨
    print("\nç¤ºä¾‹ 1: è¿›åº¦è¿½è¸ªå™¨")
    print("=" * 60)
    
    tracker = ProgressTracker(100, "æµ‹è¯•æ›´æ–°")
    for i in range(100):
        success = i % 10 != 7  # æ¨¡æ‹Ÿå¶å°”å¤±è´¥
        tracker.update(success=success, symbol=f"TEST{i}", count=5 if success else 0)
        time.sleep(0.01)
    
    tracker.print_summary()
    
    # ç¤ºä¾‹ï¼šæ‰¹æ¬¡ä¼˜åŒ–å™¨
    print("\nç¤ºä¾‹ 2: æ‰¹æ¬¡ä¼˜åŒ–å™¨")
    print("=" * 60)
    
    recommendation = batch_optimizer.get_recommendation(
        total_items=857,  # æ‰€æœ‰ä¸Šæ«ƒè‚¡ç¥¨
        days_per_item=30   # æœ€è¿‘ 30 å¤©
    )
    
    print(f"æ€»è‚¡ç¥¨æ•°: 857")
    print(f"æ—¥æœŸèŒƒå›´: 30 å¤©")
    print(f"å»ºè®®æ‰¹æ¬¡å¤§å°: {recommendation['batch_size']}")
    print(f"é¢„è®¡æ‰¹æ¬¡æ•°: {recommendation['num_batches']}")
    print(f"é¢„è®¡æ¯æ‰¹æ—¶é—´: {recommendation['estimated_time_per_batch']}")
    print(f"é¢„è®¡æ€»æ—¶é—´: {recommendation['estimated_total_time']}")
    
    # ç¤ºä¾‹ï¼šé”™è¯¯åˆ†ç±»
    print("\nç¤ºä¾‹ 3: é”™è¯¯åˆ†ç±»å™¨")
    print("=" * 60)
    
    test_errors = [
        Exception("Request timeout"),
        Exception("HTTP 500 Internal Server Error"),
        Exception("could not convert string to float: ' ---'"),
        Exception("deadlock detected"),
        Exception("Connection refused"),
    ]
    
    for error in test_errors:
        error_type, config = error_classifier.classify(error)
        print(f"é”™è¯¯: {error}")
        print(f"  ç±»å‹: {config['name']}")
        print(f"  æ˜¯å¦é‡è¯•: {'æ˜¯' if config['retry'] else 'å¦'}")
        print()
    
    error_classifier.print_statistics()
